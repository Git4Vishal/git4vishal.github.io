<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.27.3 by Michael Rose
  Copyright 2013-2025 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Building Production-Grade RAG Systems: Architecture and Best Practices - Home</title>
<meta name="description" content="Lessons learned from building and scaling RAG systems in enterprise environments—moving from proof-of-concept demos to production-grade systems that handle millions of documents and thousands of concurrent users.">


  <meta name="author" content="Vishal Sharma">
  
  <meta property="article:author" content="Vishal Sharma">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Home">
<meta property="og:title" content="Building Production-Grade RAG Systems: Architecture and Best Practices">
<meta property="og:url" content="https://git4vishal.github.io/genai/architecture/production-grade-rag-systems/">


  <meta property="og:description" content="Lessons learned from building and scaling RAG systems in enterprise environments—moving from proof-of-concept demos to production-grade systems that handle millions of documents and thousands of concurrent users.">







  <meta property="article:published_time" content="2025-12-20T12:00:00-06:00">






<link rel="canonical" href="https://git4vishal.github.io/genai/architecture/production-grade-rag-systems/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Home Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- Mermaid JS for diagram rendering -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
<script type="text/javascript">
  document.addEventListener('DOMContentLoaded', function() {
    // Convert kramdown code blocks to mermaid divs
    document.querySelectorAll('code.language-mermaid').forEach(function(code) {
      const pre = code.parentElement;
      const div = document.createElement('div');
      div.className = 'mermaid';
      div.textContent = code.textContent;
      pre.replaceWith(div);
    });

    // Initialize Mermaid
    mermaid.initialize({
      startOnLoad: true,
      theme: 'dark',
      securityLevel: 'loose'
    });
  });
</script>

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Home
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/projects/"
                
                
              >Projects</a>
            </li><li class="masthead__menu-item">
              <a
                href="/blog/"
                
                
              >Blogs</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="https://git4vishal.github.io/">
        <img src="/assets/images/bio-photo.jpg" alt="Vishal Sharma" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="https://git4vishal.github.io/" itemprop="url">Vishal Sharma</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Enterprise Data &amp; AI Platform Leader</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Frisco, Texas</span>
        </li>
      

      
        
          
            <li><a href="https://www.linkedin.com/in/sharma-vishal/" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://github.com/git4vishal" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://x.com/twitt4vishal" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i><span class="label">Twitter</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:email4vishal@gmail.com" rel="me" class="u-email">
            <meta itemprop="email" content="email4vishal@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Building Production-Grade RAG Systems: Architecture and Best Practices">
    <meta itemprop="description" content="Lessons learned from building and scaling RAG systems in enterprise environments—moving from proof-of-concept demos to production-grade systems that handle millions of documents and thousands of concurrent users.">
    <meta itemprop="datePublished" content="2025-12-20T12:00:00-06:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://git4vishal.github.io/genai/architecture/production-grade-rag-systems/" itemprop="url">Building Production-Grade RAG Systems: Architecture and Best Practices
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          9 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>Retrieval-Augmented Generation (RAG) has become the go-to pattern for building LLM applications that need to work with proprietary or current data. However, moving from a proof-of-concept RAG demo to a production-grade system requires careful consideration of architecture, evaluation, and operational concerns.</p>

<p>I’ve built and scaled RAG systems in enterprise environments, and in this post, I’ll share the lessons learned, architectural patterns, and best practices that separate production systems from demos.</p>

<h2 id="the-gap-between-demo-and-production">The Gap Between Demo and Production</h2>

<p>A basic RAG implementation might work fine for a demo:</p>

<ol>
  <li>Chunk documents</li>
  <li>Embed them in a vector database</li>
  <li>Retrieve relevant chunks on query</li>
  <li>Pass to LLM for generation</li>
</ol>

<p><strong>But production systems face challenges that demos don’t:</strong></p>

<ul>
  <li><strong>Scale</strong> - Millions of documents, thousands of concurrent users</li>
  <li><strong>Quality</strong> - Consistent, accurate responses with proper citations</li>
  <li><strong>Latency</strong> - Sub-2-second response times expected by users</li>
  <li><strong>Cost</strong> - Keeping inference costs manageable at scale</li>
  <li><strong>Monitoring</strong> - Understanding when and why the system fails</li>
  <li><strong>Security</strong> - Access control, PII handling, audit logs, compliance</li>
</ul>

<p>The gap between a working demo and a production-ready system is substantial. Let me walk through the key components and design decisions.</p>

<h2 id="production-rag-architecture">Production RAG Architecture</h2>

<p>A production-grade RAG system consists of multiple components working together:</p>

<pre><code class="language-mermaid">graph TD
    A[Document Sources] --&gt; B[Ingestion Pipeline]
    B --&gt; C[Document Processing&lt;br/&gt;Extract, Chunk, Enrich]
    C --&gt; D[Embedding Generation&lt;br/&gt;Batch Processing]
    D --&gt; E[Vector Database&lt;br/&gt;+ Metadata Store]

    F[User Query] --&gt; G[Query Processing&lt;br/&gt;Rewriting, Expansion]
    G --&gt; H[Hybrid Retrieval&lt;br/&gt;Vector + Keyword]
    E --&gt; H
    H --&gt; I[Re-ranking&lt;br/&gt;Cross-Encoder]
    I --&gt; J[Context Assembly&lt;br/&gt;Citation Formatting]
    J --&gt; K[LLM Generation&lt;br/&gt;with Citations]
    K --&gt; L[Response Validation&lt;br/&gt;Citation Check]
    L --&gt; M[User Response]

    N[Monitoring &amp; Logging] -.-&gt; B
    N -.-&gt; H
    N -.-&gt; K
    N -.-&gt; L
</code></pre>

<p>Each component requires careful design for production use. Let’s dive into the critical ones.</p>

<h2 id="1-document-ingestion-pipeline">1. Document Ingestion Pipeline</h2>

<p><strong>The Challenge:</strong></p>
<ul>
  <li>Handling diverse document types (PDF, Word, HTML, Markdown, code)</li>
  <li>Preserving document structure and metadata</li>
  <li>Incremental updates without full reprocessing</li>
  <li>Managing document versions and deletions</li>
</ul>

<p><strong>Production Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ingest_document</span><span class="p">(</span><span class="n">doc_path</span><span class="p">,</span> <span class="n">metadata</span><span class="p">):</span>
    <span class="c1"># Extract text preserving structure
</span>    <span class="n">content</span> <span class="o">=</span> <span class="nf">extract_with_structure</span><span class="p">(</span><span class="n">doc_path</span><span class="p">)</span>

    <span class="c1"># Smart chunking strategy
</span>    <span class="n">chunks</span> <span class="o">=</span> <span class="nf">smart_chunking</span><span class="p">(</span>
        <span class="n">content</span><span class="p">,</span>
        <span class="n">chunk_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>        <span class="c1"># Tokens, not characters
</span>        <span class="n">overlap</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>            <span class="c1"># Overlap for context continuity
</span>        <span class="n">respect_boundaries</span><span class="o">=</span><span class="bp">True</span>  <span class="c1"># Don't split sentences/paragraphs
</span>    <span class="p">)</span>

    <span class="c1"># Enrich with metadata for filtering and ranking
</span>    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">:</span>
        <span class="n">chunk</span><span class="p">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span>
            <span class="o">**</span><span class="n">metadata</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">source</span><span class="sh">'</span><span class="p">:</span> <span class="n">doc_path</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">chunk_id</span><span class="sh">'</span><span class="p">:</span> <span class="n">chunk</span><span class="p">.</span><span class="nb">id</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">parent_doc_id</span><span class="sh">'</span><span class="p">:</span> <span class="n">doc</span><span class="p">.</span><span class="nb">id</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">timestamp</span><span class="sh">'</span><span class="p">:</span> <span class="nf">now</span><span class="p">(),</span>
            <span class="sh">'</span><span class="s">version</span><span class="sh">'</span><span class="p">:</span> <span class="n">doc</span><span class="p">.</span><span class="n">version</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">access_level</span><span class="sh">'</span><span class="p">:</span> <span class="n">doc</span><span class="p">.</span><span class="n">access_level</span>  <span class="c1"># For security
</span>        <span class="p">}</span>

    <span class="c1"># Batch embed and store
</span>    <span class="n">embeddings</span> <span class="o">=</span> <span class="nf">embed_batch</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span>
    <span class="n">vector_db</span><span class="p">.</span><span class="nf">upsert</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Key Decisions:</strong></p>

<ol>
  <li><strong>Chunking Strategy</strong>
    <ul>
      <li>Fixed-size (256-1024 tokens) with overlap for context preservation</li>
      <li>Semantic chunking (split on section/paragraph boundaries)</li>
      <li>Hybrid: fixed size with boundary respect</li>
    </ul>
  </li>
  <li><strong>Metadata Schema</strong>
    <ul>
      <li>Source document identifier</li>
      <li>Temporal info (created, modified dates)</li>
      <li>Categorical info (document type, department, product)</li>
      <li>Access control attributes</li>
    </ul>
  </li>
  <li><strong>Update Strategy</strong>
    <ul>
      <li>Incremental: Track document versions, only reprocess changes</li>
      <li>Deletion handling: Soft delete with tombstone records</li>
      <li>Refresh frequency: Real-time vs batch daily/weekly</li>
    </ul>
  </li>
</ol>

<h2 id="2-hybrid-retrieval-strategy">2. Hybrid Retrieval Strategy</h2>

<p>Basic vector similarity search alone isn’t sufficient for production quality.</p>

<p><strong>Why Hybrid Search?</strong></p>
<ul>
  <li>Vector search: Captures semantic similarity</li>
  <li>Keyword search (BM25): Captures exact matches and rare terms</li>
  <li>Combined: Better recall and precision</li>
</ul>

<p><strong>Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">retrieve</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="c1"># Parallel retrieval from multiple sources
</span>    <span class="n">vector_results</span> <span class="o">=</span> <span class="nf">vector_search</span><span class="p">(</span>
        <span class="n">query</span><span class="p">,</span>
        <span class="n">k</span><span class="o">=</span><span class="n">top_k</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">filters</span><span class="o">=</span><span class="n">filters</span>  <span class="c1"># Pre-filter by metadata
</span>    <span class="p">)</span>

    <span class="n">keyword_results</span> <span class="o">=</span> <span class="nf">bm25_search</span><span class="p">(</span>
        <span class="n">query</span><span class="p">,</span>
        <span class="n">k</span><span class="o">=</span><span class="n">top_k</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">filters</span><span class="o">=</span><span class="n">filters</span>
    <span class="p">)</span>

    <span class="c1"># Combine and deduplicate
</span>    <span class="n">combined</span> <span class="o">=</span> <span class="nf">merge_results</span><span class="p">(</span><span class="n">vector_results</span><span class="p">,</span> <span class="n">keyword_results</span><span class="p">)</span>

    <span class="c1"># Re-rank using cross-encoder for final ranking
</span>    <span class="n">reranked</span> <span class="o">=</span> <span class="nf">cross_encoder_rerank</span><span class="p">(</span>
        <span class="n">query</span><span class="p">,</span>
        <span class="n">combined</span><span class="p">,</span>
        <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">reranked</span>
</code></pre></div></div>

<p><strong>Advanced Techniques:</strong></p>

<ul>
  <li><strong>Query Rewriting:</strong> Expand or clarify ambiguous user queries</li>
  <li><strong>Metadata Filtering:</strong> Narrow search by date range, source, document type</li>
  <li><strong>Re-ranking:</strong> Cross-encoders provide superior relevance at the cost of latency</li>
  <li><strong>Parent-Child Retrieval:</strong> Retrieve small chunks, expand to parent document for context</li>
</ul>

<p><strong>Performance Optimization:</strong></p>
<ul>
  <li>Cache embeddings for frequently accessed queries</li>
  <li>Use approximate nearest neighbor (ANN) algorithms (HNSW, IVF)</li>
  <li>Partition vector database by metadata for faster filtering</li>
</ul>

<h2 id="3-context-assembly-and-token-management">3. Context Assembly and Token Management</h2>

<p>How you assemble context for the LLM significantly impacts quality and cost.</p>

<p><strong>The Challenge:</strong></p>
<ul>
  <li>Limited context window (even with 128K+ context models)</li>
  <li>Token costs increase linearly with context size</li>
  <li>Balancing retrieval quantity vs relevance</li>
</ul>

<p><strong>Smart Context Assembly:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">assemble_context</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">chunks</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">4000</span><span class="p">):</span>
    <span class="n">context_parts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">token_count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">chunks</span><span class="p">):</span>
        <span class="c1"># Accurate token counting
</span>        <span class="n">chunk_tokens</span> <span class="o">=</span> <span class="nf">count_tokens</span><span class="p">(</span><span class="n">chunk</span><span class="p">.</span><span class="n">text</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">token_count</span> <span class="o">+</span> <span class="n">chunk_tokens</span> <span class="o">&gt;</span> <span class="n">max_tokens</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="c1"># Format with citation metadata
</span>        <span class="n">context_parts</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
            <span class="sa">f</span><span class="sh">"</span><span class="s">[Source </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="sh">'</span><span class="s">source</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="sh">"</span>
            <span class="sa">f</span><span class="sh">"</span><span class="s">Page </span><span class="si">{</span><span class="n">chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">page</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">N/A</span><span class="sh">'</span><span class="p">)</span><span class="si">}</span><span class="s">]</span><span class="se">\n</span><span class="sh">"</span>
            <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">chunk</span><span class="p">.</span><span class="n">text</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span>
        <span class="p">)</span>
        <span class="n">token_count</span> <span class="o">+=</span> <span class="n">chunk_tokens</span>

    <span class="k">return</span> <span class="sh">"</span><span class="se">\n</span><span class="s">---</span><span class="se">\n</span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">context_parts</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Considerations:</strong></p>

<ol>
  <li><strong>Token Budget Allocation</strong>
    <ul>
      <li>Reserve 70% for context, 30% for generation</li>
      <li>Dynamic allocation based on query complexity</li>
    </ul>
  </li>
  <li><strong>Citation Format</strong>
    <ul>
      <li>Inline citations for traceability</li>
      <li>Unique identifiers for each source</li>
      <li>Include page numbers, sections for PDF/documents</li>
    </ul>
  </li>
  <li><strong>Handling Contradictions</strong>
    <ul>
      <li>Present multiple perspectives when documents conflict</li>
      <li>Use temporal ordering (favor recent information)</li>
      <li>Explicitly note contradictions in context</li>
    </ul>
  </li>
</ol>

<h2 id="4-generation-with-citations">4. Generation with Citations</h2>

<p>Users need to verify LLM responses—citations are critical for trust.</p>

<p><strong>Prompt Engineering:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">system_prompt</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">
You are an assistant that answers questions based on provided context.

CRITICAL RULES:
1. Only use information from the provided context
2. Cite sources using [Source X] format inline
3. If context doesn</span><span class="sh">'</span><span class="s">t contain the answer, explicitly say </span><span class="sh">"</span><span class="s">I don</span><span class="sh">'</span><span class="s">t have enough information</span><span class="sh">"</span><span class="s">
4. Do not make up information or hallucinate facts
5. When sources contradict, present both perspectives

Context:
{context}

Question: {query}

Provide a clear, concise answer with inline citations.
</span><span class="sh">"""</span>
</code></pre></div></div>

<p><strong>Post-Processing Validation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">validate_response</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">retrieved_chunks</span><span class="p">):</span>
    <span class="c1"># Extract cited sources from response
</span>    <span class="n">cited_sources</span> <span class="o">=</span> <span class="nf">extract_citations</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>

    <span class="c1"># Verify all citations exist in retrieved chunks
</span>    <span class="n">valid_citations</span> <span class="o">=</span> <span class="nf">all</span><span class="p">(</span>
        <span class="n">source</span> <span class="ow">in</span> <span class="n">retrieved_chunks</span> <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">cited_sources</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_citations</span><span class="p">:</span>
        <span class="nf">log_warning</span><span class="p">(</span><span class="sh">"</span><span class="s">Invalid citations detected</span><span class="sh">"</span><span class="p">)</span>
        <span class="c1"># Option: Regenerate or flag for review
</span>
    <span class="c1"># Add clickable links to sources
</span>    <span class="n">response_with_links</span> <span class="o">=</span> <span class="nf">add_source_links</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">retrieved_chunks</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">response_with_links</span>
</code></pre></div></div>

<p><strong>Best Practices:</strong></p>
<ul>
  <li>Enforce citation requirements in system prompts</li>
  <li>Validate citations in post-processing</li>
  <li>Provide direct links to source documents</li>
  <li>Show confidence scores when available (model-dependent)</li>
</ul>

<h2 id="5-evaluation-framework">5. Evaluation Framework</h2>

<p><strong>You can’t improve what you don’t measure.</strong></p>

<p>Production RAG systems require comprehensive evaluation across multiple dimensions:</p>

<p><strong>Evaluation Metrics:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RAGEvaluator</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">test_set</span><span class="p">):</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">retrieval_metrics</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span>
                <span class="sh">'</span><span class="s">precision_at_k</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
                <span class="sh">'</span><span class="s">recall_at_k</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
                <span class="sh">'</span><span class="s">mrr</span><span class="sh">'</span><span class="p">:</span> <span class="p">[]</span>  <span class="c1"># Mean Reciprocal Rank
</span>            <span class="p">},</span>
            <span class="sh">'</span><span class="s">generation_metrics</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span>
                <span class="sh">'</span><span class="s">answer_relevance</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
                <span class="sh">'</span><span class="s">answer_correctness</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
                <span class="sh">'</span><span class="s">citation_accuracy</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
                <span class="sh">'</span><span class="s">hallucination_rate</span><span class="sh">'</span><span class="p">:</span> <span class="p">[]</span>
            <span class="p">},</span>
            <span class="sh">'</span><span class="s">operational_metrics</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span>
                <span class="sh">'</span><span class="s">latency_p50</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
                <span class="sh">'</span><span class="s">latency_p95</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
                <span class="sh">'</span><span class="s">cost_per_query</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
                <span class="sh">'</span><span class="s">error_rate</span><span class="sh">'</span><span class="p">:</span> <span class="p">[]</span>
            <span class="p">}</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">test_set</span><span class="p">:</span>
            <span class="c1"># Measure retrieval quality
</span>            <span class="n">retrieved</span> <span class="o">=</span> <span class="nf">retrieve</span><span class="p">(</span><span class="n">example</span><span class="p">.</span><span class="n">query</span><span class="p">)</span>
            <span class="n">results</span><span class="p">[</span><span class="sh">'</span><span class="s">retrieval_metrics</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">precision_at_k</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span>
                <span class="nf">precision_at_k</span><span class="p">(</span><span class="n">retrieved</span><span class="p">,</span> <span class="n">example</span><span class="p">.</span><span class="n">relevant_docs</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Measure generation quality
</span>            <span class="n">answer</span> <span class="o">=</span> <span class="nf">generate</span><span class="p">(</span><span class="n">example</span><span class="p">.</span><span class="n">query</span><span class="p">,</span> <span class="n">retrieved</span><span class="p">)</span>
            <span class="n">results</span><span class="p">[</span><span class="sh">'</span><span class="s">generation_metrics</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">answer_relevance</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span>
                <span class="nf">llm_as_judge</span><span class="p">(</span><span class="n">example</span><span class="p">.</span><span class="n">query</span><span class="p">,</span> <span class="n">answer</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Validate citations
</span>            <span class="n">results</span><span class="p">[</span><span class="sh">'</span><span class="s">generation_metrics</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">citation_accuracy</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span>
                <span class="nf">validate_citations</span><span class="p">(</span><span class="n">answer</span><span class="p">,</span> <span class="n">retrieved</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="nf">aggregate_metrics</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Evaluation Approaches:</strong></p>

<ol>
  <li><strong>Human Evaluation</strong>
    <ul>
      <li>Gold standard but expensive</li>
      <li>Use for test set creation (200-500 examples)</li>
      <li>Ongoing spot-checking (50 queries/week)</li>
    </ul>
  </li>
  <li><strong>LLM-as-Judge</strong>
    <ul>
      <li>Automated relevance and correctness scoring</li>
      <li>Cost-effective for continuous evaluation</li>
      <li>Validate against human judgments periodically</li>
    </ul>
  </li>
  <li><strong>Automated Metrics</strong>
    <ul>
      <li>RAGAS framework (retrieval + generation metrics)</li>
      <li>BERTScore, ROUGE for answer quality</li>
      <li>Exact match for factual questions</li>
    </ul>
  </li>
</ol>

<p><strong>Continuous Evaluation:</strong></p>
<ul>
  <li>Weekly automated evaluation on held-out test set</li>
  <li>A/B testing for major changes (new embedding model, chunking strategy)</li>
  <li>User feedback loops (thumbs up/down, detailed feedback)</li>
</ul>

<h2 id="6-monitoring-and-observability">6. Monitoring and Observability</h2>

<p>Production systems require real-time monitoring to catch issues before users do.</p>

<p><strong>Instrumentation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rag_pipeline</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tracer</span><span class="p">.</span><span class="nf">start_span</span><span class="p">(</span><span class="sh">"</span><span class="s">rag_query</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">span</span><span class="p">:</span>
        <span class="n">span</span><span class="p">.</span><span class="nf">set_attribute</span><span class="p">(</span><span class="sh">"</span><span class="s">query_length</span><span class="sh">"</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">query</span><span class="p">))</span>

        <span class="c1"># Retrieval phase
</span>        <span class="k">with</span> <span class="n">tracer</span><span class="p">.</span><span class="nf">start_span</span><span class="p">(</span><span class="sh">"</span><span class="s">retrieval</span><span class="sh">"</span><span class="p">):</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
            <span class="n">chunks</span> <span class="o">=</span> <span class="nf">retrieve</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
            <span class="n">retrieval_latency</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

            <span class="n">span</span><span class="p">.</span><span class="nf">set_attribute</span><span class="p">(</span><span class="sh">"</span><span class="s">num_chunks_retrieved</span><span class="sh">"</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">chunks</span><span class="p">))</span>
            <span class="n">span</span><span class="p">.</span><span class="nf">set_attribute</span><span class="p">(</span><span class="sh">"</span><span class="s">retrieval_latency_ms</span><span class="sh">"</span><span class="p">,</span> <span class="n">retrieval_latency</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>

        <span class="c1"># Generation phase
</span>        <span class="k">with</span> <span class="n">tracer</span><span class="p">.</span><span class="nf">start_span</span><span class="p">(</span><span class="sh">"</span><span class="s">generation</span><span class="sh">"</span><span class="p">):</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
            <span class="n">response</span> <span class="o">=</span> <span class="nf">generate</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">chunks</span><span class="p">)</span>
            <span class="n">generation_latency</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

            <span class="n">span</span><span class="p">.</span><span class="nf">set_attribute</span><span class="p">(</span><span class="sh">"</span><span class="s">response_length</span><span class="sh">"</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">response</span><span class="p">))</span>
            <span class="n">span</span><span class="p">.</span><span class="nf">set_attribute</span><span class="p">(</span><span class="sh">"</span><span class="s">generation_latency_ms</span><span class="sh">"</span><span class="p">,</span> <span class="n">generation_latency</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>

        <span class="c1"># Cost tracking
</span>        <span class="n">embedding_cost</span> <span class="o">=</span> <span class="nf">calculate_cost</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">query</span><span class="p">),</span> <span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">embedding</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">llm_cost</span> <span class="o">=</span> <span class="nf">calculate_cost</span><span class="p">(</span>
            <span class="nf">count_tokens</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span> <span class="o">+</span> <span class="nf">len</span><span class="p">(</span><span class="n">response</span><span class="p">),</span>
            <span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">llm</span><span class="sh">"</span>
        <span class="p">)</span>
        <span class="n">total_cost</span> <span class="o">=</span> <span class="n">embedding_cost</span> <span class="o">+</span> <span class="n">llm_cost</span>

        <span class="nf">log_metrics</span><span class="p">({</span>
            <span class="sh">'</span><span class="s">total_latency</span><span class="sh">'</span><span class="p">:</span> <span class="n">retrieval_latency</span> <span class="o">+</span> <span class="n">generation_latency</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">cost_per_query</span><span class="sh">'</span><span class="p">:</span> <span class="n">total_cost</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">num_chunks</span><span class="sh">'</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span>
        <span class="p">})</span>

        <span class="k">return</span> <span class="n">response</span>
</code></pre></div></div>

<p><strong>Observability Stack:</strong></p>

<ul>
  <li><strong>LLM Tracing:</strong> LangSmith, Weights &amp; Biases, Phoenix</li>
  <li><strong>Metrics:</strong> Prometheus + Grafana</li>
  <li><strong>Logging:</strong> ELK Stack (Elasticsearch, Logstash, Kibana)</li>
  <li><strong>Alerting:</strong> PagerDuty for SLA violations</li>
</ul>

<p><strong>Key Dashboards:</strong></p>

<ol>
  <li><strong>System Health</strong>
    <ul>
      <li>Request rate, error rate, latency (p50, p95, p99)</li>
      <li>Vector DB query performance</li>
      <li>LLM API availability and rate limits</li>
    </ul>
  </li>
  <li><strong>Quality Metrics</strong>
    <ul>
      <li>Average retrieval precision</li>
      <li>Citation accuracy rate</li>
      <li>User satisfaction scores (thumbs up/down ratio)</li>
    </ul>
  </li>
  <li><strong>Cost Management</strong>
    <ul>
      <li>Cost per query (embedding + LLM)</li>
      <li>Daily/monthly cost trends</li>
      <li>Cost by user segment or use case</li>
    </ul>
  </li>
</ol>

<h2 id="common-pitfalls-and-solutions">Common Pitfalls and Solutions</h2>

<h3 id="1-chunking-too-large-or-too-small">1. Chunking Too Large or Too Small</h3>

<p><strong>Problem:</strong></p>
<ul>
  <li><strong>Too large (&gt;1024 tokens):</strong> Irrelevant information dilutes the signal, confuses LLM</li>
  <li><strong>Too small (&lt;128 tokens):</strong> Loses context, requires more chunks, increases cost</li>
</ul>

<p><strong>Solution:</strong></p>
<ul>
  <li>Test multiple chunk sizes on your specific data (typically 256-1024 tokens)</li>
  <li>Use semantic chunking for structured documents (sections, paragraphs)</li>
  <li>Add chunk overlap (10-20%) to preserve context across boundaries</li>
</ul>

<h3 id="2-ignoring-metadata">2. Ignoring Metadata</h3>

<p><strong>Problem:</strong> Treating all documents equally leads to poor relevance</p>

<p><strong>Solution:</strong></p>
<ul>
  <li>Capture rich metadata: date, source, document type, department, product line</li>
  <li>Use metadata for pre-filtering before vector search</li>
  <li>Boost recent documents or authoritative sources in ranking</li>
</ul>

<h3 id="3-no-failure-modes">3. No Failure Modes</h3>

<p><strong>Problem:</strong> System fails ungracefully when retrieval finds nothing relevant</p>

<p><strong>Solution:</strong></p>
<ul>
  <li>Implement explicit “I don’t have enough information” responses</li>
  <li>Fallback strategies: broader search, suggest related topics</li>
  <li>Set minimum confidence thresholds for responses</li>
</ul>

<h3 id="4-not-testing-adversarially">4. Not Testing Adversarially</h3>

<p><strong>Problem:</strong> System works on happy path but fails on edge cases</p>

<p><strong>Solution:</strong></p>
<ul>
  <li>Test with ambiguous queries (“What is the status?” without context)</li>
  <li>Test with contradictory documents (policy changes over time)</li>
  <li>Test with outdated information (documents before recent updates)</li>
  <li>Simulate malicious inputs (prompt injection attempts)</li>
</ul>

<h3 id="5-ignoring-cost-at-scale">5. Ignoring Cost at Scale</h3>

<p><strong>Problem:</strong></p>
<ul>
  <li>Retrieving 20 chunks × 512 tokens = 10K+ input tokens per query</li>
  <li>At 10K queries/day, costs add up quickly</li>
</ul>

<p><strong>Solution:</strong></p>
<ul>
  <li>Optimize chunk count (test 5, 10, 15 chunks)</li>
  <li>Use cheaper models for re-ranking (smaller cross-encoders)</li>
  <li>Cache embeddings for frequently asked questions</li>
  <li>Implement query deduplication</li>
</ul>

<h2 id="real-world-results">Real-World Results</h2>

<p>In a recent enterprise RAG deployment for internal documentation:</p>

<p><strong>System Metrics:</strong></p>
<ul>
  <li><strong>Accuracy:</strong> 87% answer correctness (vs 94% for human experts)</li>
  <li><strong>Latency:</strong> p50=1.2s, p95=2.8s (hybrid retrieval + reranking)</li>
  <li><strong>Cost:</strong> $0.03 per query average (10K queries/day = $300/day)</li>
  <li><strong>Adoption:</strong> 10K+ queries/day after 3 months, 85% user satisfaction</li>
</ul>

<p><strong>Key Success Factors:</strong></p>

<ol>
  <li><strong>Hybrid Retrieval:</strong> Improved precision by 23% vs vector-only</li>
  <li><strong>Re-ranking:</strong> Reduced hallucinations by 40% by surfacing truly relevant chunks</li>
  <li><strong>Citation Enforcement:</strong> 92% of users clicked on sources to verify answers</li>
  <li><strong>Continuous Evaluation:</strong> Caught 3 regressions before user reports</li>
</ol>

<p><strong>Optimization Journey:</strong></p>

<ul>
  <li><strong>Week 1-2:</strong> Basic vector search, 65% accuracy, 3.5s p95 latency</li>
  <li><strong>Week 3-4:</strong> Added keyword search, 78% accuracy, 3.2s latency</li>
  <li><strong>Week 5-6:</strong> Added re-ranking, 85% accuracy, 2.9s latency</li>
  <li><strong>Week 7-8:</strong> Optimized chunking and metadata filtering, 87% accuracy, 2.8s latency</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<p><strong>1. Start Simple, Iterate Based on Data</strong></p>
<ul>
  <li>Don’t over-engineer version 1</li>
  <li>Ship basic RAG, measure, identify bottlenecks</li>
  <li>Add complexity only where data shows it’s needed</li>
</ul>

<p><strong>2. Evaluation is Not Optional</strong></p>
<ul>
  <li>Build evaluation framework from Day 1</li>
  <li>Automated metrics + human evaluation</li>
  <li>Continuous monitoring, not one-time testing</li>
</ul>

<p><strong>3. Retrieval Quality &gt; LLM Choice</strong></p>
<ul>
  <li>Better chunks → better answers</li>
  <li>Invest in hybrid search, re-ranking, metadata filtering</li>
  <li>LLM upgrade provides marginal gains vs retrieval improvements</li>
</ul>

<p><strong>4. Citations Build Trust</strong></p>
<ul>
  <li>Users need to verify answers, especially in enterprise settings</li>
  <li>Inline citations with source links</li>
  <li>Citation accuracy as a key metric</li>
</ul>

<p><strong>5. Monitor Everything</strong></p>
<ul>
  <li>You’ll be surprised what users ask</li>
  <li>Track queries, failures, edge cases</li>
  <li>Use insights to improve retrieval and prompts</li>
</ul>

<p><strong>6. Cost Optimization Matters</strong></p>
<ul>
  <li>Monitor cost per query from Day 1</li>
  <li>Optimize chunk count, embedding model, LLM choice</li>
  <li>Cache frequently accessed data</li>
</ul>

<h2 id="next-steps">Next Steps</h2>

<p>In future posts, I’ll dive deeper into:</p>

<ul>
  <li><strong>Vector Database Selection:</strong> Benchmarking Pinecone, Weaviate, Qdrant, pgvector</li>
  <li><strong>Advanced Chunking Strategies:</strong> Semantic chunking, document structure preservation</li>
  <li><strong>Cost Optimization:</strong> Reducing LLM costs by 70% without quality loss</li>
  <li><strong>Multi-Modal RAG:</strong> Handling images, tables, charts in documents</li>
</ul>

<h2 id="resources">Resources</h2>

<p><strong>Frameworks &amp; Tools:</strong></p>
<ul>
  <li><a href="https://python.langchain.com/docs/use_cases/question_answering/">LangChain RAG Tutorial</a></li>
  <li><a href="https://docs.llamaindex.ai/">LlamaIndex Documentation</a></li>
  <li><a href="https://github.com/explodinggradients/ragas">RAGAS Evaluation Framework</a></li>
</ul>

<p><strong>Further Reading:</strong></p>
<ul>
  <li><a href="https://www.anthropic.com/index/building-effective-agents">Anthropic: Retrieval-Augmented Generation Guide</a></li>
  <li><a href="https://platform.openai.com/docs/guides/retrieval-augmented-generation">OpenAI: RAG Best Practices</a></li>
</ul>

<p><strong>Disclaimer:</strong> The views, opinions, and technical approaches shared in this post are my own, based on my personal experience building production RAG systems. They do not represent the views of my current or former employers. Technology choices and architectural decisions should always be evaluated in the context of your specific use case and requirements.</p>

<p><strong>Questions or experiences to share?</strong> I’d love to hear about your RAG implementations and challenges. Connect with me:</p>

<table>
  <tbody>
    <tr>
      <td><strong>Contact:</strong> <a href="https://www.linkedin.com/in/sharma-vishal/"><i class="fas fa-fw fa-link"></i> LinkedIn</a></td>
      <td><a href="https://github.com/git4vishal"><i class="fab fa-fw fa-github"></i> GitHub</a></td>
      <td><a href="https://x.com/twitt4vishal"><i class="fab fa-fw fa-twitter-square"></i> X</a></td>
      <td><a href="mailto:email4vishal@gmail.com"><i class="fas fa-fw fa-envelope"></i> Email</a></td>
    </tr>
  </tbody>
</table>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#architecture" class="page__taxonomy-item p-category" rel="tag">Architecture</a><span class="sep">, </span>
    
      <a href="/tags/#best-practices" class="page__taxonomy-item p-category" rel="tag">Best Practices</a><span class="sep">, </span>
    
      <a href="/tags/#genai" class="page__taxonomy-item p-category" rel="tag">GenAI</a><span class="sep">, </span>
    
      <a href="/tags/#llm" class="page__taxonomy-item p-category" rel="tag">LLM</a><span class="sep">, </span>
    
      <a href="/tags/#production" class="page__taxonomy-item p-category" rel="tag">Production</a><span class="sep">, </span>
    
      <a href="/tags/#rag" class="page__taxonomy-item p-category" rel="tag">RAG</a><span class="sep">, </span>
    
      <a href="/tags/#vector-search" class="page__taxonomy-item p-category" rel="tag">Vector Search</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#architecture" class="page__taxonomy-item p-category" rel="tag">architecture</a><span class="sep">, </span>
    
      <a href="/categories/#genai" class="page__taxonomy-item p-category" rel="tag">genai</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2025-12-20T12:00:00-06:00">December 20, 2025</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="/evaluation/testing/evaluating-llm-applications/" class="pagination--pager" title="Evaluating LLM Applications: Beyond Vibes and Into Data">Previous</a>
    
    
      <a href="/case-study/platform-engineering/genai-customer-analysis-case-study/" class="pagination--pager" title="Case Study: Production GenAI Platform Processing 2M+ Monthly Customer Interactions">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
    
<div class="page__related">
  
  <h2 class="page__related-title">You May Also Enjoy</h2>
  <div class="grid__wrapper">
    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/case-study/platform-engineering/genai-customer-analysis-case-study/" rel="permalink">Case Study: Production GenAI Platform Processing 2M+ Monthly Customer Interactions
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">How I architected a production GenAI platform processing 2M+ monthly call transcripts with 85% accuracy, delivering $1.2M annual retention value through serv...</p>
  </article>
</div>

    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/evaluation/testing/evaluating-llm-applications/" rel="permalink">Evaluating LLM Applications: Beyond Vibes and Into Data
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          10 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Rigorous evaluation is what separates prototypes from production LLM systems. Learn the frameworks, metrics, and best practices for measuring what matters in...</p>
  </article>
</div>

    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/governance/strategy/ai-governance-framework/" rel="permalink">Building an AI Governance Framework for Enterprise GenAI Adoption
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">As enterprises rush to adopt GenAI, many overlook a critical question: How do we govern these systems responsibly?
</p>
  </article>
</div>

    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/optimization/cost/llm-cost-optimization/" rel="permalink">LLM Cost Optimization: Cutting Your AI Bill by 70% Without Sacrificing Quality
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          9 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">When we first deployed our RAG system to production, our LLM costs were $12,000/month for 50,000 queries. Six months later, we’re handling 200,000 queries at...</p>
  </article>
</div>

    
  </div>
</div>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        

<center>
<div class="page__footer-follow">
    <ul class="social-icons">
        

        <b>Contact: </b>
        
        
        
        <li><a href="https://www.linkedin.com/in/sharma-vishal/" rel="nofollow noopener noreferrer"><i
                class="fas fa-fw fa-link" aria-hidden="true"></i> LinkedIn</a></li>
        
        
        
        <li><a href="https://github.com/git4vishal" rel="nofollow noopener noreferrer"><i
                class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
        
        
        <li><a href="https://x.com/twitt4vishal" rel="nofollow noopener noreferrer"><i
                class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
        
        
        <li><a href="mailto:email4vishal@gmail.com" rel="nofollow noopener noreferrer"><i
                class="fab fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
        
        
        

        
        <li>
            <a href="/feed.xml"><i
                    class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
        
    </ul>
</div>


<div class="page__footer-copyright">&copy;
    
    
        2025 -
    
    2026
    <a href="https://git4vishal.github.io">
        Vishal Sharma | Enterprise Data &amp; AI Platform Leader
    </a>.
<!--    Powered by -->
<!--    <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> -->
<!--    &amp; -->
<!--    <a href="https://mademistakes.com/work/jekyll-themes/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a>.-->
</div>
</center>
      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>






  </body>
</html>
